{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The API: Connecting to BigML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The BigML API offers an endpoint to create, get, update and delete every Machine Learning resource. <br/>\n",
    "This API is accessible via HTTP and its general public domain is [bigml.io](https://bigml.io). <br/>\n",
    "You will need some credentials that will be used to authenticate every request. <br/>\n",
    "We recommend to set them in environment variables for your convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BIGML_USERNAME=merce_demo\n",
      "env: BIGML_API_KEY=dc0d33828c638840934f8bc004099b41d664b421\n"
     ]
    }
   ],
   "source": [
    "# set your credentials as environment variables\n",
    "%env BIGML_USERNAME=merce_demo\n",
    "%env BIGML_API_KEY=dc0d33828c638840934f8bc004099b41d664b421"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API calls that you will need to issue contain these credentials as authentication token. For instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://bigml.io/source?username=merce_demo;api_key=dc0d33828c638840934f8bc004099b41d664b421;limit=1\n"
     ]
    }
   ],
   "source": [
    "url = \"https://bigml.io/source?username=merce_demo;api_key=dc0d33828c638840934f8bc004099b41d664b421;limit=1\"\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"meta\": {\"limit\": 1, \"next\": \"/andromeda/source?username=merce_demo&api_key=dc0d33828c638840934f8bc004099b41d664b421&limit=1&offset=1\", \"offset\": 0, \"previous\": null, \"total_count\": 179}, \"objects\": [{\"category\": 12, \"charset\": \"UTF-8\", \"code\": 200, \"configuration\": null, \"configuration_status\": false, \"content_type\": \"text/csv\", \"created\": \"2018-09-10T15:17:09.644000\", \"creator\": \"merce_demo\", \"credits\": 0, \"description\": \"Created using BigMLer\", \"disable_datetime\": false, \"field_types\": {\"categorical\": 2, \"datetime\": 1, \"items\": 0, \"numeric\": 15, \"text\": 1, \"total\": 19}, \"fields_meta\": {\"count\": 19, \"limit\": 1000, \"offset\": 0, \"query_total\": 19, \"total\": 19}, \"file_name\": \"ext_diabetes.csv\", \"item_analysis\": {}, \"md5\": \"6d6af57ac5fe8484e9ddede6a18a8e57\", \"name\": \"BigMLer_MonSep1018_171708\", \"name_options\": \"19 fields (2 categorical, 15 numeric, 1 text, 6 auto-generated datetime)\", \"number_of_anomalies\": 0, \"number_of_anomalyscores\": 0, \"number_of_associations\": 0, \"number_of_associationsets\": 0, \"number_of_centroids\": 0, \"number_of_clusters\": 0, \"number_of_correlations\": 0, \"number_of_datasets\": 2, \"number_of_deepnets\": 0, \"number_of_ensembles\": 0, \"number_of_forecasts\": 0, \"number_of_logisticregressions\": 0, \"number_of_models\": 1, \"number_of_optimls\": 0, \"number_of_predictions\": 0, \"number_of_statisticaltests\": 0, \"number_of_timeseries\": 0, \"number_of_topicdistributions\": 0, \"number_of_topicmodels\": 0, \"private\": true, \"project\": null, \"resource\": \"source/5b968af52774cb43d1001e7a\", \"shared\": false, \"size\": 12263, \"source_parser\": {\"header\": true, \"locale\": \"en_US\", \"missing_tokens\": [\"\", \"NaN\", \"NULL\", \"N/A\", \"null\", \"-\", \"#REF!\", \"#VALUE!\", \"?\", \"#NULL!\", \"#NUM!\", \"#DIV/0\", \"n/a\", \"#NAME?\", \"NIL\", \"nil\", \"na\", \"#N/A\", \"NA\"], \"quote\": \"\\\"\", \"separator\": \",\"}, \"status\": {\"code\": 5, \"elapsed\": 818, \"message\": \"The source has been created\", \"progress\": 1}, \"subscription\": false, \"tags\": [\"BigMLer\", \"BigMLer_MonSep1018_171708\"], \"term_analysis\": {\"enabled\": true}, \"type\": 0, \"updated\": \"2018-09-10T16:07:15.312000\"}]}"
     ]
    }
   ],
   "source": [
    "!curl \"https://bigml.io/source?username=$BIGML_USERNAME;api_key=$BIGML_API_KEY;limit=1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lists the last previously uploaded file in your account.<br/>\n",
    "Managing resources using these raw HTTP calls is, of course, possible but not optimal.<br/>\n",
    "Bindings to several languages will make easier resource management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The bindings: connecting to BigML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, this notebook uses the **Python bindings library** and **BigMLer**, a command line utility, to access the BigML API. \n",
    "Please, check the **quick start** section of [BigMLer's documentation](http://bigmler.readthedocs.org/en/latest/#quick-start) to know how to **install** and remember to [set your **credentials**](http://bigml.readthedocs.org/en/latest/#authentication) before using **BigMLer** or the bindings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://bigml.io/andromeda/?username=merce_demo;api_key=dc0d33828c638840934f8bc004099b41d664b421;\n"
     ]
    }
   ],
   "source": [
    "from bigml.api import BigML\n",
    "api = BigML() # Credentials are imported from environment variables\n",
    "              # BIGML_USERNAME and BIGML_API_KEY.\n",
    "              # They can also be set explicitly: api = BigML([username], [api_key])\n",
    "print(api.url + api.auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data dictionary operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example uses a **Diabetes dataset**, which contains information about several features that might or might not be related to the users diagnose. The goal is predicting which features can influence the diagnose and predicting if a new user will have diabetes. The data looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>plasma glucose</th>\n",
       "      <th>blood pressure</th>\n",
       "      <th>triceps skin thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diabetes pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>medication</th>\n",
       "      <th>observations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>04/01/16 18:43</td>\n",
       "      <td>6.0</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>627</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>diazepam;enalapril</td>\n",
       "      <td>hepatItis antecents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>05/01/16 00:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>351</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>06/01/16 17:17</td>\n",
       "      <td>8.0</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>672</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>simvastatin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11/01/16 15:07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>167</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>12/01/16 03:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2288</td>\n",
       "      <td>33</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient id       timestamp  pregnancies  plasma glucose  blood pressure  \\\n",
       "0           1  04/01/16 18:43          6.0             148              72   \n",
       "1           2  05/01/16 00:20          1.0              85              66   \n",
       "2           3  06/01/16 17:17          8.0             183              64   \n",
       "3           4  11/01/16 15:07          1.0              89              66   \n",
       "4           5  12/01/16 03:12          NaN             137              40   \n",
       "\n",
       "   triceps skin thickness  insulin   bmi  diabetes pedigree  age diabetes  \\\n",
       "0                      35        0  33.6                627   50     True   \n",
       "1                      29        0  26.6                351   31    False   \n",
       "2                       0        0  23.3                672   32     True   \n",
       "3                      23       94  28.1                167   21    False   \n",
       "4                      35      168  43.1               2288   33     True   \n",
       "\n",
       "           medication         observations  \n",
       "0  diazepam;enalapril  hepatItis antecents  \n",
       "1                 NaN                  NaN  \n",
       "2         simvastatin                  NaN  \n",
       "3                 NaN                  NaN  \n",
       "4                 NaN                  NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from pprint import pprint, pformat\n",
    "from IPython.display import display\n",
    "# DIABETES_FILE = 'https://static.bigml.com/csv/ext_diabetes.csv' # you can also import from a remote file\n",
    "DIABETES_FILE = 'data/ext_diabetes.csv'\n",
    "display(pd.read_csv(DIABETES_FILE, nrows=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's upload this file and see how this content is interpreted from the Machine Learning point of view.<br/>\n",
    "We'll first create a **Project**, an organizational unit to store every resource generated in this session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CREATING PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"VSSML18 Python bindings example\"\n",
    "project = api.create_project({'name': PROJECT_NAME})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Projects** and **predictions** are the only resources that are **synchronous** in **BigML**, meaning that when you issue the create call the response you get is never a work in process, but the final resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 201,\n",
      " 'error': None,\n",
      " 'location': 'http://bigml.io/andromeda/project/5b96b41e92527314e1001ef9',\n",
      " 'object': {'category': 0,\n",
      "            'code': 201,\n",
      "            'configuration': None,\n",
      "            'configuration_status': False,\n",
      "            'created': '2018-09-10T18:12:46.166550',\n",
      "            'creator': 'merce_demo',\n",
      "            'description': '',\n",
      "            'execution_id': None,\n",
      "            'execution_status': None,\n",
      "            'manage_permission': [],\n",
      "            'name': 'VSSML18 Python bindings example',\n",
      "            'name_options': '',\n",
      "            'private': True,\n",
      "            'resource': 'project/5b96b41e92527314e1001ef9',\n",
      "            'stats': {'anomalies': {'count': 0},\n",
      "                      'anomalyscores': {'count': 0},\n",
      "                      'associations': {'count': 0},\n",
      "                      'associationsets': {'count': 0},\n",
      "                      'batchanomalyscores': {'count': 0},\n",
      "                      'batchcentroids': {'count': 0},\n",
      "                      'batchpredictions': {'count': 0},\n",
      "                      'batchtopicdistributions': {'count': 0},\n",
      "                      'centroids': {'count': 0},\n",
      "                      'clusters': {'count': 0},\n",
      "                      'composites': {'count': 0},\n",
      "                      'configurations': {'count': 0},\n",
      "                      'correlations': {'count': 0},\n",
      "                      'datasets': {'count': 0},\n",
      "                      'deepnets': {'count': 0},\n",
      "                      'ensembles': {'count': 0},\n",
      "                      'evaluations': {'count': 0},\n",
      "                      'executions': {'count': 0},\n",
      "                      'forecasts': {'count': 0},\n",
      "                      'fusions': {'count': 0},\n",
      "                      'libraries': {'count': 0},\n",
      "                      'logisticregressions': {'count': 0},\n",
      "                      'models': {'count': 0},\n",
      "                      'optimls': {'count': 0},\n",
      "                      'predictions': {'count': 0},\n",
      "                      'samples': {'count': 0},\n",
      "                      'scripts': {'count': 0},\n",
      "                      'sources': {'count': 0},\n",
      "                      'statisticaltests': {'count': 0},\n",
      "                      'timeseries': {'count': 0},\n",
      "                      'topicdistributions': {'count': 0},\n",
      "                      'topicmodels': {'count': 0}},\n",
      "            'status': {'code': 5,\n",
      "                       'message': 'The project has been created',\n",
      "                       'progress': 1},\n",
      "            'tags': [],\n",
      "            'type': 0,\n",
      "            'updated': '2018-09-10T18:12:46.166572',\n",
      "            'user_metadata': {}},\n",
      " 'resource': 'project/5b96b41e92527314e1001ef9'}\n"
     ]
    }
   ],
   "source": [
    "pprint(project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first level attributes of this dictionary contain:\n",
    "\n",
    "- code: the HTTP response status code\n",
    "- error: the error information (when an HTTP error occurs)\n",
    "- location: the location to access the resource\n",
    "- object: the API's response\n",
    "- resource: the **resource ID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROJECT = project['resource']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of resources in **BigML** are **asynchronous**, so you will need polling for the resource till it is either finished or faulty. We'll see the first example now, when we upload our data to the platform and create a **source**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### CREATING SOURCE\n",
    "When data is uploaded to the platform a **source** is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 201,\n",
      " 'error': None,\n",
      " 'location': 'http://bigml.io/andromeda/source/5b96b50a2774cb43d1001f65',\n",
      " 'object': {'category': 0,\n",
      "            'code': 201,\n",
      "            'configuration': None,\n",
      "            'configuration_status': False,\n",
      "            'content_type': 'text/csv',\n",
      "            'created': '2018-09-10T18:16:42.836014',\n",
      "            'creator': 'merce_demo',\n",
      "            'credits': 0.0,\n",
      "            'description': '',\n",
      "            'disable_datetime': False,\n",
      "            'field_types': {'categorical': 0,\n",
      "                            'datetime': 0,\n",
      "                            'items': 0,\n",
      "                            'numeric': 0,\n",
      "                            'text': 0,\n",
      "                            'total': 0},\n",
      "            'fields_meta': {'count': 0, 'limit': 1000, 'offset': 0, 'total': 0},\n",
      "            'file_name': 'ext_diabetes.csv',\n",
      "            'item_analysis': {},\n",
      "            'md5': '6d6af57ac5fe8484e9ddede6a18a8e57',\n",
      "            'name': 'diabetes source',\n",
      "            'name_options': '',\n",
      "            'number_of_anomalies': 0,\n",
      "            'number_of_anomalyscores': 0,\n",
      "            'number_of_associations': 0,\n",
      "            'number_of_associationsets': 0,\n",
      "            'number_of_centroids': 0,\n",
      "            'number_of_clusters': 0,\n",
      "            'number_of_correlations': 0,\n",
      "            'number_of_datasets': 0,\n",
      "            'number_of_deepnets': 0,\n",
      "            'number_of_ensembles': 0,\n",
      "            'number_of_forecasts': 0,\n",
      "            'number_of_logisticregressions': 0,\n",
      "            'number_of_models': 0,\n",
      "            'number_of_optimls': 0,\n",
      "            'number_of_predictions': 0,\n",
      "            'number_of_statisticaltests': 0,\n",
      "            'number_of_timeseries': 0,\n",
      "            'number_of_topicdistributions': 0,\n",
      "            'number_of_topicmodels': 0,\n",
      "            'private': True,\n",
      "            'project': 'project/5b96b41e92527314e1001ef9',\n",
      "            'resource': 'source/5b96b50a2774cb43d1001f65',\n",
      "            'shared': False,\n",
      "            'size': 12263,\n",
      "            'source_parser': {},\n",
      "            'status': {'code': 1,\n",
      "                       'message': 'The source creation request has been queued '\n",
      "                                  'and will be processed soon',\n",
      "                       'progress': 0},\n",
      "            'subscription': False,\n",
      "            'tags': ['bindings example', 'diabetes'],\n",
      "            'term_analysis': {},\n",
      "            'type': 0,\n",
      "            'updated': '2018-09-10T18:16:42.836036'},\n",
      " 'resource': 'source/5b96b50a2774cb43d1001f65'}\n"
     ]
    }
   ],
   "source": [
    "source = api.create_source(DIABETES_FILE,\n",
    "                           {'name': 'diabetes source', \\\n",
    "                            'tags': ['bindings example', 'diabetes'], \\\n",
    "                            'project': PROJECT})\n",
    "\"\"\"\n",
    "    CSV, ARFF, Excel and JSON files, either local or remote, can be uploaded.\n",
    "    For instance, you could use a remote diabetes:\n",
    "    DIABETES_FILE = \"https://static.bigml.com/csv/diabetes.csv\"\n",
    "    \n",
    "\"\"\"\n",
    "pprint(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this response does not contain any of the uploaded information yet. The **status** of the resource shows that the source creation request is in process. We'll have to wait for this process to finish. This is what **api.ok** does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category': 0,\n",
      " 'charset': 'UTF-8',\n",
      " 'code': 200,\n",
      " 'configuration': None,\n",
      " 'configuration_status': False,\n",
      " 'content_type': 'text/csv',\n",
      " 'created': '2018-09-10T18:16:42.836000',\n",
      " 'creator': 'merce_demo',\n",
      " 'credits': 0,\n",
      " 'description': '',\n",
      " 'disable_datetime': False,\n",
      " 'field_types': {'categorical': 2,\n",
      "                 'datetime': 1,\n",
      "                 'items': 0,\n",
      "                 'numeric': 15,\n",
      "                 'text': 1,\n",
      "                 'total': 19},\n",
      " 'fields': {'000000': {'column_number': 0,\n",
      "                       'name': 'patient id',\n",
      "                       'optype': 'numeric',\n",
      "                       'order': 0},\n",
      "            '000001': {'child_ids': ['000001-0',\n",
      "                                     '000001-1',\n",
      "                                     '000001-2',\n",
      "                                     '000001-3',\n",
      "                                     '000001-4',\n",
      "                                     '000001-5'],\n",
      "                       'column_number': 1,\n",
      "                       'name': 'timestamp',\n",
      "                       'optype': 'datetime',\n",
      "                       'order': 1,\n",
      "                       'time_formats': ['us-date-minute', 'eu-date-minute']},\n",
      "            '000001-0': {'auto_generated': True,\n",
      "                         'column_number': 13,\n",
      "                         'datatype': 'year',\n",
      "                         'name': 'timestamp.year',\n",
      "                         'optype': 'numeric',\n",
      "                         'order': 13,\n",
      "                         'parent_ids': ['000001'],\n",
      "                         'parent_optype': 'datetime'},\n",
      "            '000001-1': {'auto_generated': True,\n",
      "                         'column_number': 14,\n",
      "                         'datatype': 'month',\n",
      "                         'name': 'timestamp.month',\n",
      "                         'optype': 'numeric',\n",
      "                         'order': 14,\n",
      "                         'parent_ids': ['000001'],\n",
      "                         'parent_optype': 'datetime'},\n",
      "            '000001-2': {'auto_generated': True,\n",
      "                         'column_number': 15,\n",
      "                         'datatype': 'day-of-month',\n",
      "                         'name': 'timestamp.day-of-month',\n",
      "                         'optype': 'numeric',\n",
      "                         'order': 15,\n",
      "                         'parent_ids': ['000001'],\n",
      "                         'parent_optype': 'datetime'},\n",
      "            '000001-3': {'auto_generated': True,\n",
      "                         'column_number': 16,\n",
      "                         'datatype': 'day-of-week',\n",
      "                         'name': 'timestamp.day-of-week',\n",
      "                         'optype': 'numeric',\n",
      "                         'order': 16,\n",
      "                         'parent_ids': ['000001'],\n",
      "                         'parent_optype': 'datetime'},\n",
      "            '000001-4': {'auto_generated': True,\n",
      "                         'column_number': 17,\n",
      "                         'datatype': 'hour',\n",
      "                         'name': 'timestamp.hour',\n",
      "                         'optype': 'numeric',\n",
      "                         'order': 17,\n",
      "                         'parent_ids': ['000001'],\n",
      "                         'parent_optype': 'datetime'},\n",
      "            '000001-5': {'auto_generated': True,\n",
      "                         'column_number': 18,\n",
      "                         'datatype': 'minute',\n",
      "                         'name': 'timestamp.minute',\n",
      "                         'optype': 'numeric',\n",
      "                         'order': 18,\n",
      "                         'parent_ids': ['000001'],\n",
      "                         'parent_optype': 'datetime'},\n",
      "            '000002': {'column_number': 2,\n",
      "                       'name': 'pregnancies',\n",
      "                       'optype': 'numeric',\n",
      "                       'order': 2},\n",
      "            '000003': {'column_number': 3,\n",
      "                       'name': 'plasma glucose',\n",
      "                       'optype': 'numeric',\n",
      "                       'order': 3},\n",
      "            '000004': {'column_number': 4,\n",
      "                       'name': 'blood pressure',\n",
      "                       'optype': 'numeric',\n",
      "                       'order': 4},\n",
      "            '000005': {'column_number': 5,\n",
      "                       'name': 'triceps skin thickness',\n",
      "                       'optype': 'numeric',\n",
      "                       'order': 5},\n",
      "            '000006': {'column_number': 6,\n",
      "                       'name': 'insulin',\n",
      "                       'optype': 'numeric',\n",
      "                       'order': 6},\n",
      "            '000007': {'column_number': 7,\n",
      "                       'name': 'bmi',\n",
      "                       'optype': 'numeric',\n",
      "                       'order': 7},\n",
      "            '000008': {'column_number': 8,\n",
      "                       'name': 'diabetes pedigree',\n",
      "                       'optype': 'numeric',\n",
      "                       'order': 8},\n",
      "            '000009': {'column_number': 9,\n",
      "                       'name': 'age',\n",
      "                       'optype': 'numeric',\n",
      "                       'order': 9},\n",
      "            '00000a': {'column_number': 10,\n",
      "                       'name': 'diabetes',\n",
      "                       'optype': 'categorical',\n",
      "                       'order': 10,\n",
      "                       'term_analysis': {'enabled': True}},\n",
      "            '00000b': {'column_number': 11,\n",
      "                       'name': 'medication',\n",
      "                       'optype': 'categorical',\n",
      "                       'order': 11,\n",
      "                       'term_analysis': {'enabled': True}},\n",
      "            '00000c': {'column_number': 12,\n",
      "                       'name': 'observations',\n",
      "                       'optype': 'text',\n",
      "                       'order': 12,\n",
      "                       'term_analysis': {'case_sensitive': False,\n",
      "                                         'enabled': True,\n",
      "                                         'language': 'en',\n",
      "                                         'stem_words': True,\n",
      "                                         'stopword_removal': 'selected_language',\n",
      "                                         'token_mode': 'all',\n",
      "                                         'use_stopwords': False}}},\n",
      " 'fields_meta': {'count': 19,\n",
      "                 'limit': 1000,\n",
      "                 'offset': 0,\n",
      "                 'query_total': 19,\n",
      "                 'total': 19},\n",
      " 'file_name': 'ext_diabetes.csv',\n",
      " 'item_analysis': {},\n",
      " 'md5': '6d6af57ac5fe8484e9ddede6a18a8e57',\n",
      " 'name': 'diabetes source',\n",
      " 'name_options': '19 fields (2 categorical, 15 numeric, 1 text, 6 '\n",
      "                 'auto-generated datetime)',\n",
      " 'number_of_anomalies': 0,\n",
      " 'number_of_anomalyscores': 0,\n",
      " 'number_of_associations': 0,\n",
      " 'number_of_associationsets': 0,\n",
      " 'number_of_centroids': 0,\n",
      " 'number_of_clusters': 0,\n",
      " 'number_of_correlations': 0,\n",
      " 'number_of_datasets': 0,\n",
      " 'number_of_deepnets': 0,\n",
      " 'number_of_ensembles': 0,\n",
      " 'number_of_forecasts': 0,\n",
      " 'number_of_logisticregressions': 0,\n",
      " 'number_of_models': 0,\n",
      " 'number_of_optimls': 0,\n",
      " 'number_of_predictions': 0,\n",
      " 'number_of_statisticaltests': 0,\n",
      " 'number_of_timeseries': 0,\n",
      " 'number_of_topicdistributions': 0,\n",
      " 'number_of_topicmodels': 0,\n",
      " 'private': True,\n",
      " 'project': 'project/5b96b41e92527314e1001ef9',\n",
      " 'resource': 'source/5b96b50a2774cb43d1001f65',\n",
      " 'shared': False,\n",
      " 'size': 12263,\n",
      " 'source_parser': {'header': True,\n",
      "                   'locale': 'en_US',\n",
      "                   'missing_tokens': ['',\n",
      "                                      'NaN',\n",
      "                                      'NULL',\n",
      "                                      'N/A',\n",
      "                                      'null',\n",
      "                                      '-',\n",
      "                                      '#REF!',\n",
      "                                      '#VALUE!',\n",
      "                                      '?',\n",
      "                                      '#NULL!',\n",
      "                                      '#NUM!',\n",
      "                                      '#DIV/0',\n",
      "                                      'n/a',\n",
      "                                      '#NAME?',\n",
      "                                      'NIL',\n",
      "                                      'nil',\n",
      "                                      'na',\n",
      "                                      '#N/A',\n",
      "                                      'NA'],\n",
      "                   'quote': '\"',\n",
      "                   'separator': ','},\n",
      " 'status': {'code': 5,\n",
      "            'elapsed': 1413,\n",
      "            'message': 'The source has been created',\n",
      "            'progress': 1},\n",
      " 'subscription': False,\n",
      " 'tags': ['bindings example', 'diabetes'],\n",
      " 'term_analysis': {'enabled': True},\n",
      " 'type': 0,\n",
      " 'updated': '2018-09-10T18:16:44.429000'}\n"
     ]
    }
   ],
   "source": [
    "api.ok(source)\n",
    "pprint(source[\"object\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**api.ok** waits for the source creation to finish and updates the contents of the **source** variable with the current remote version of the source. Thus, now we can see that the **source** variable contains the description of the fields inferred from the uploaded file. We'll write two auxiliar functions using **api.ok** to show the resources once they are finished or to warn us about any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check(resource):\n",
    "    \"\"\"\n",
    "        Checks whether the resource status is *finished* or\n",
    "        prints an error if something fails.\n",
    "    \"\"\"\n",
    "    # api.ok uses api.get_[resouce_type] to retrieve the status of the resource\n",
    "    # till it reaches a final state (either FINISHED or FAULTY)\n",
    "    # as defined in \n",
    "    if not api.ok(resource):\n",
    "        print(\"Error!!!: Failed to create resource %s\" % \\\n",
    "            resource.get(\n",
    "                'resource',\n",
    "                resource.get('object', {}).get('name')))\n",
    "\n",
    "def check_and_show(resource):\n",
    "    \"\"\"\n",
    "        Checks whether the resource status is *finished*\n",
    "        and shows its contents or prints an error if something failed.\n",
    "    \"\"\"\n",
    "    check(resource)\n",
    "    pprint(resource)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View source in BIGML's web site\n",
    "As all **BigML**'s applications work on top of the same **API**, the source we've just created appears immediately in the source listings of our web dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://bigml.com/dashboard/sources\n"
     ]
    }
   ],
   "source": [
    "BIGML_DASHBOARD_URL = 'https://bigml.com/dashboard'\n",
    "sources_list_url = \"%s/sources\" % BIGML_DASHBOARD_URL\n",
    "print(sources_list_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is uploaded, we'd need to check that the **fields** characteristics inferred in our **source** are really the expected ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fields class: working with fields\n",
    "What's the field structure that was inferred from the first lines of the file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bigml.fields import Fields\n",
    "fields = Fields(source) # retrieves the field structure from the source object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **fields** attribute in **Fields** contains the complete fields structure information as a dictionary.<br/>\n",
    "It also has auxiliary functions to produce the field attributes, like the ID associated to each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'00000b'\n"
     ]
    }
   ],
   "source": [
    "pprint(fields.field_id(\"medication\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UPDATING SOURCE: changing fields type\n",
    "If you need to change any of the inferred types, just update your source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# medication was inferred to be a categorical field, it really is an items field\n",
    "# To update fields attributes, the expected format of the update body is\n",
    "# {\"fields\": {[field_id1]: {[field_attribute1]: [new_field_attribute1_value], \n",
    "#                          [field_attribute2]: [new_field_attribute2_value]},\n",
    "#             [field_id2]: {[field_attribute1]: [new_field_attribute1_value[,\n",
    "#                           [field_attribute2]: [new_field_attribute2_value]]}}\n",
    "\n",
    "fields_change  = {\n",
    "    fields.field_id('medication'): {'optype': 'items',\n",
    "                                    'item_analysis': {'separator': ';'}}}\n",
    "# updating the source structure\n",
    "source = api.update_source(source,\n",
    "                           {\"fields\": fields_change,\n",
    "                            \"name\": \"modified diabetes\"})\n",
    "check(source)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source has been updated and the field contents should be analyzed like a list of **items**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'items'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = Fields(source)\n",
    "fields.fields[fields.field_id(\"medication\")][\"optype\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, a **categorical** field could be turned into a **text** field and their associated properties:\n",
    "```\n",
    "{\n",
    "    \"enabled\": true,\n",
    "    \"use_stopwords\": true,\n",
    "    \"stem_words\": true,\n",
    "    \"case_sensitive\": false,\n",
    "    \"language\": \"en\",\n",
    "    \"token_mode\": \"tokens_only\"\n",
    "}\n",
    "```\n",
    "could be changed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missings can be a source of information in your data. For a correct management of missing values, we need to identify some strings that usually can be considered as such. These are considered **missing tokens**.<br/>\n",
    "In the example data, the field **bmi** contains a \"no data\" string which should be interpreted as a missing value.<br/>\n",
    "We can extend the list of missing values used by default in the **Source** adding this string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'NaN', 'NULL', 'N/A', 'no data', 'null', '-', '#REF!', '#VALUE!']\n",
      "['#NULL!', '#NUM!', '#DIV/0', 'n/a', '#NAME?', 'NIL', 'nil', 'na', '#N/A', 'NA']\n"
     ]
    }
   ],
   "source": [
    "# updating the source structure\n",
    "\n",
    "missing_tokens = fields.missing_tokens\n",
    "missing_tokens.append(\"no data\")\n",
    "source = api.update_source( \\\n",
    "    source,\n",
    "    {'source_parser': {\"missing_tokens\": missing_tokens,\n",
    "                       \"locale\": \"es-ES\"}})\n",
    "check(source)\n",
    "fields = Fields(source)\n",
    "\n",
    "pprint(fields.missing_tokens[0: 9])\n",
    "pprint(fields.missing_tokens[10: 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your **missings** have been correctly identified, it's time to analyze the full contents of the file and create a **Dataset** that summarizes it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset will provide information about **errors**, **missing** values in fields and **histograms**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = api.create_dataset(source)\n",
    "check(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The diabetes field contains:  {'categories': [['false', 119], ['true', 81]], 'missing_count': 0}\n",
      "The bmi field has 3 missing values\n",
      "The pregnancies field has 11 missing values\n"
     ]
    }
   ],
   "source": [
    "fields = Fields(dataset)\n",
    "print(\"The diabetes field contains: \", pformat(fields.fields[fields.field_id(\"diabetes\")][\"summary\"]))\n",
    "print(\"The bmi field has\", pformat(fields.fields[fields.field_id(\"bmi\")][\"summary\"][\"missing_count\"]) , \"missing values\")\n",
    "print(\"The pregnancies field has\", pformat(fields.fields[fields.field_id(\"pregnancies\")][\"summary\"][\"missing_count\"]) , \"missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summaries show the number of **missings** and **errors** and we can decide what to do with them.<br/>\n",
    "Some models can consider missing as a new value. In the field **pregnancies** we could associate it to the fact that the patient is a man.<br/>\n",
    "In this case, the model can be built to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = api.create_model(dataset, {\"missing_splits\": True})\n",
    "check(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other models, like **Clusters** cannot use the rows that have missing values. In this case, these rows are discarded when building the model unless the\n",
    "missing values are replaced with a sensible default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_args = {\"default_numeric_value\": \"mean\"}\n",
    "cluster = api.create_cluster(dataset, cluster_args)\n",
    "check(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing a new example, let's inspect this damaged **churn telemcom** dataset, where other datasets have been merged by mistake.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account length</th>\n",
       "      <th>Area code</th>\n",
       "      <th>International plan</th>\n",
       "      <th>Voice mail plan</th>\n",
       "      <th>Number vmail messages</th>\n",
       "      <th>Total day minutes</th>\n",
       "      <th>Total day calls</th>\n",
       "      <th>Total day charge</th>\n",
       "      <th>Total eve minutes</th>\n",
       "      <th>Total eve calls</th>\n",
       "      <th>Total eve charge</th>\n",
       "      <th>Total night minutes</th>\n",
       "      <th>Total night calls</th>\n",
       "      <th>Total night charge</th>\n",
       "      <th>Total intl minutes</th>\n",
       "      <th>Total intl calls</th>\n",
       "      <th>Total intl charge</th>\n",
       "      <th>Customer service calls</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  Account length  Area code International plan Voice mail plan  \\\n",
       "0    KS             128        415                 No             Yes   \n",
       "1    OH             107        415                 No             Yes   \n",
       "2    NJ             137        415                 No              No   \n",
       "3    OH              84        408                Yes              No   \n",
       "4    OK              75        415                Yes              No   \n",
       "\n",
       "   Number vmail messages  Total day minutes  Total day calls  \\\n",
       "0                     25              265.1              110   \n",
       "1                     26              161.6              123   \n",
       "2                      0              243.4              114   \n",
       "3                      0              299.4               71   \n",
       "4                      0              166.7              113   \n",
       "\n",
       "   Total day charge  Total eve minutes  Total eve calls  Total eve charge  \\\n",
       "0             45.07              197.4               99             16.78   \n",
       "1             27.47              195.5              103             16.62   \n",
       "2             41.38              121.2              110             10.30   \n",
       "3             50.90               61.9               88              5.26   \n",
       "4             28.34              148.3              122             12.61   \n",
       "\n",
       "   Total night minutes  Total night calls  Total night charge  \\\n",
       "0                244.7                 91               11.01   \n",
       "1                254.4                103               11.45   \n",
       "2                162.6                104                7.32   \n",
       "3                196.9                 89                8.86   \n",
       "4                186.9                121                8.41   \n",
       "\n",
       "   Total intl minutes  Total intl calls  Total intl charge  \\\n",
       "0                10.0                 3               2.70   \n",
       "1                13.7                 3               3.70   \n",
       "2                12.2                 5               3.29   \n",
       "3                 6.6                 7               1.78   \n",
       "4                10.1                 3               2.73   \n",
       "\n",
       "   Customer service calls  Churn  \n",
       "0                       1  False  \n",
       "1                       1  False  \n",
       "2                       0  False  \n",
       "3                       2  False  \n",
       "4                       3  False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CHURN_FILE = 'https://static.bigml.com/csv/churn-telecom.csv' # you can also import from a remote file\n",
    "CHURN_FILE = 'data/churn-telecom.csv'\n",
    "display(pd.read_csv(CHURN_FILE, nrows=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset should contain information about telecom accounts, where the last field **Churn** should be **True** if the user has churned and **False** otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_churn_source = api.create_source(CHURN_FILE, \\\n",
    "                                       {\"name\": \"Dirty churn\",\n",
    "                                        \"tags\": [\"bindings example\", \"dirty churn\"], \\\n",
    "                                        \"project\": project[\"resource\"]})\n",
    "api.ok(dirty_churn_source)\n",
    "dirty_churn_dataset = api.create_dataset(dirty_churn_source)\n",
    "api.ok(dirty_churn_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the contents of the **Churn** field, we see that that's it has some unexpected values. We should remove the rows affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4335\n",
      "The Churn field contains:  {'categories': [['False', 2849],\n",
      "                ['yes', 963],\n",
      "                ['True', 483],\n",
      "                ['no', 37],\n",
      "                ['Falsecsv/groceries2.csv\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x000000644\\x000001753\\x000001753\\x0000001757705\\x0013250330501\\x00013742\\x00 '\n",
      "                 '0\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00ustar  '\n",
      "                 '\\x00canals\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00canals\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00products',\n",
      "                 1],\n",
      "                ['foreign_worker', 1],\n",
      "                ['marital-status', 1]],\n",
      " 'missing_count': 0}\n"
     ]
    }
   ],
   "source": [
    "fields = Fields(dirty_churn_dataset)\n",
    "print(dirty_churn_dataset['object']['rows'])\n",
    "print(\"The Churn field contains: \", pformat(fields.fields[fields.field_id(\"Churn\")][\"summary\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3332\n",
      "The Churn field contains:  {'categories': [['False', 2849], ['True', 483]], 'missing_count': 0}\n"
     ]
    }
   ],
   "source": [
    "clean_churn_dataset = api.create_dataset(dirty_churn_dataset, { \\\n",
    "    \"lisp_filter\": \"(or (= (f \\\"Churn\\\") \\\"True\\\") (= (f \\\"Churn\\\") \\\"False\\\"))\", \\\n",
    "    \"name\": \"Clean Churn\"})\n",
    "check(clean_churn_dataset)\n",
    "print(clean_churn_dataset['object']['rows'])\n",
    "fields = Fields(clean_churn_dataset)\n",
    "print(\"The Churn field contains: \", pformat(fields.fields[fields.field_id(\"Churn\")][\"summary\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "New fields can help improve the performance of models. The **Churn** dataset has several fields that can be combined to generate new features, like ratios of charge per call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [fields.field_name(col) for col in range(0, len(fields.fields))]\n",
    "prefix_fields = [name[0: -7] for name in names if name.endswith(\"charge\")]\n",
    "field_expressions = \" \".join([\"(/ (f \\\"%s charge\\\") (f \\\"%s calls\\\"))\" % ( \\\n",
    "    prefix_fields[index], prefix_fields[index]) \\\n",
    "    for index in range(0, len(prefix_fields))])\n",
    "fields_generator = [{\"names\": [\"%s charge per call\" % name for name in prefix_fields],\n",
    "                     \"fields\": \"(list %s)\" % field_expressions}]\n",
    "extended_dataset = api.create_dataset(clean_churn_dataset, {\"new_fields\": fields_generator})\n",
    "api.ok(extended_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the performance, we split the dataset into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset: 2665 instances\n",
      "test dataset: 667 instances\n"
     ]
    }
   ],
   "source": [
    "# To ensure deterministic results, you must set the seed value\n",
    "SEED = \"BigML\"\n",
    "train_dataset = api.create_dataset(extended_dataset,\n",
    "                                   {'name': 'Churn train dataset (80%)',\n",
    "                                    'sample_rate': 0.8,\n",
    "                                    'seed': SEED})\n",
    "check(train_dataset)\n",
    "# The out_of_bag flag selects the instances left out in the previous dataset\n",
    "test_dataset = api.create_dataset(extended_dataset,\n",
    "                                  {'name': 'Churn test dataset (20%)',\n",
    "                                   'sample_rate': 0.8,\n",
    "                                   'out_of_bag': True,\n",
    "                                   'seed': SEED})\n",
    "check(test_dataset)\n",
    "print(\"train dataset: %s instances\" % train_dataset[\"object\"][\"rows\"])\n",
    "print(\"test dataset: %s instances\" % test_dataset[\"object\"][\"rows\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Account length                  : numeric         : 1       ]\n",
      "[International plan              : categorical     : 3       ]\n",
      "[Number vmail messages           : numeric         : 5       ]\n",
      "[Total day calls                 : numeric         : 7       ]\n",
      "[Total day charge                : numeric         : 8       ]\n",
      "[Total eve calls                 : numeric         : 10      ]\n",
      "[Total eve charge                : numeric         : 11      ]\n",
      "[Total night minutes             : numeric         : 12      ]\n",
      "[Total night calls               : numeric         : 13      ]\n",
      "[Total night charge              : numeric         : 14      ]\n",
      "[Total intl minutes              : numeric         : 15      ]\n",
      "[Total intl calls                : numeric         : 16      ]\n",
      "[Customer service calls          : numeric         : 18      ]\n",
      "[Churn                           : categorical     : 19      ]\n"
     ]
    }
   ],
   "source": [
    "# In our example, we will exclude the new fields first,\n",
    "excluded_fields = [\"%s charge per call\" % prefix for prefix in prefix_fields]\n",
    "\n",
    "# aternatively, you could write the list of fields to be included\n",
    "# usign \"input_fields\"\n",
    "original_model = api.create_model( \\\n",
    "    train_dataset,\n",
    "    {'name': \"Churn original fields\",\n",
    "     'objective_field': \"Churn\",\n",
    "     'excluded_fields': excluded_fields})\n",
    "\n",
    "check(original_model)\n",
    "used_fields = Fields(original_model[\"object\"][\"model\"][\"model_fields\"])\n",
    "used_fields.list_fields()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91454\n"
     ]
    }
   ],
   "source": [
    "original_evaluation = api.create_evaluation(original_model, test_dataset, {\"name\": \"Churn original fields\"})\n",
    "api.ok(original_evaluation)\n",
    "print(original_evaluation['object']['result']['model']['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Account length                  : numeric         : 1       ]\n",
      "[International plan              : categorical     : 3       ]\n",
      "[Number vmail messages           : numeric         : 5       ]\n",
      "[Total day minutes               : numeric         : 6       ]\n",
      "[Total day calls                 : numeric         : 7       ]\n",
      "[Total eve minutes               : numeric         : 9       ]\n",
      "[Total eve calls                 : numeric         : 10      ]\n",
      "[Total night minutes             : numeric         : 12      ]\n",
      "[Total night calls               : numeric         : 13      ]\n",
      "[Total intl minutes              : numeric         : 15      ]\n",
      "[Total intl calls                : numeric         : 16      ]\n",
      "[Customer service calls          : numeric         : 18      ]\n",
      "[Churn                           : categorical     : 19      ]\n",
      "[Total day charge per call       : numeric         : 20      ]\n",
      "[Total eve charge per call       : numeric         : 21      ]\n",
      "[Total night charge per call     : numeric         : 22      ]\n",
      "[Total intl charge per call      : numeric         : 23      ]\n"
     ]
    }
   ],
   "source": [
    "# We will exclude now the original charge fields\n",
    "excluded_fields = [\"%s charge\" % prefix for prefix in prefix_fields]\n",
    "\n",
    "# aternatively, you could write the list of fields to be included\n",
    "# usign \"input_fields\"\n",
    "ratio_model = api.create_model( \\\n",
    "    train_dataset,\n",
    "    {'name': \"Churn ration fields\",\n",
    "     'objective_field': \"Churn\",\n",
    "     'excluded_fields': excluded_fields})\n",
    "\n",
    "check(ratio_model)\n",
    "used_fields = Fields(ratio_model[\"object\"][\"model\"][\"model_fields\"])\n",
    "used_fields.list_fields()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91754\n"
     ]
    }
   ],
   "source": [
    "ratio_evaluation = api.create_evaluation(ratio_model, test_dataset, {\"name\": \"Churn ratio fields\"})\n",
    "api.ok(ratio_evaluation)\n",
    "print(ratio_evaluation['object']['result']['model']['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model tuning\n",
    "Depending on your data, some configuration choices can produce better adapted models. As an example, using wights to balance the instances that end in churn can help the model to detect the patterns for this especially interesting class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_model = api.create_model( \\\n",
    "    train_dataset,\n",
    "    {'name': \"Churn ration fields\",\n",
    "     'objective_field': \"Churn\",\n",
    "     'balance_objective': True,\n",
    "     'excluded_fields': excluded_fields})\n",
    "balanced_evaluation = api.create_evaluation(balanced_model, test_dataset, {\"name\": \"Churn ratio fields\"})\n",
    "api.ok(balanced_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio model recall: 0.66279\n",
      "Balanced model recall: 0.67442\n"
     ]
    }
   ],
   "source": [
    "def get_metrics(evaluation, class_name):\n",
    "    \"\"\" Returns the evaluation metrics corresponding to a particular class\n",
    "    \n",
    "    \"\"\"\n",
    "    for class_info in evaluation['object']['result']['model']['per_class_statistics']:\n",
    "        if class_info[\"class_name\"] == class_name:\n",
    "            return class_info\n",
    "        \n",
    "print(\"Ratio model recall:\", get_metrics(ratio_evaluation, \"True\")[\"recall\"])\n",
    "print(\"Balanced model recall:\", get_metrics(balanced_evaluation, \"True\")[\"recall\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREDICTIONS INTEGRATION\n",
    "Eventually, the goal of our models will usually be creating predictions. Predictions can be created remotely by providing the new input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: True\n",
      "confidence: 0.52627\n",
      "path: [{'operator': '>', 'field': '000006', 'value': 244.67063}, {'operator': '<=', 'field': '000005', 'value': 5}]\n"
     ]
    }
   ],
   "source": [
    "input_data = {'Total day minutes': 320, 'Number vmail messages': 2}\n",
    "prediction = api.create_prediction(ratio_model,\n",
    "                                   input_data=input_data)\n",
    "check(prediction)\n",
    "print(\"prediction: %s\" % prediction[\"object\"][\"output\"])\n",
    "print(\"confidence: %s\" % prediction[\"object\"][\"confidence\"])\n",
    "print(\"path: %s\" % prediction[\"object\"][\"prediction_path\"][\"path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, this method has latencies involved every time you make a prediction. If your predictions don't need to be immediate, then you can store the input data in a file and do a batch prediction with an entire dataset of it. We can use our test dataset to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_prediction = api.create_batch_prediction(\\\n",
    "    ratio_model, test_dataset, \\\n",
    "    {\"all_fields\": True,\n",
    "     \"output_dataset\": True})\n",
    "check(batch_prediction)\n",
    "# we could download the results as a CSV using\n",
    "# api.download_batch_prediction(batch_prediction,\n",
    "#     filename='my_dir/my_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model class: using the model locally to predict\n",
    "The JSON model that can be downloaded via the API has all the information needed to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/churn_model.json'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOCAL_MODEL_FILE = \"data/churn_model.json\"\n",
    "api.export(ratio_model, LOCAL_MODEL_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The local **Model** object adds a **predict** method that can be used locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'confidence': 0.52627,\n",
      " 'count': 232,\n",
      " 'distribution': [['True', 137], ['False', 95]],\n",
      " 'distribution_unit': 'categories',\n",
      " 'next': 'Total eve minutes',\n",
      " 'path': ['Total day minutes > 244.67063', 'Number vmail messages <= 5'],\n",
      " 'prediction': 'True',\n",
      " 'probability': 0.5886221807084364}\n"
     ]
    }
   ],
   "source": [
    "from bigml.model import Model\n",
    "\"\"\"\n",
    "    The **Model** object can use the contents of a Model\n",
    "    previously stored in a file or\n",
    "    internally download the model JSON structure once and\n",
    "    store it in a local directory for further use.\n",
    "\"\"\"\n",
    "local_model = Model(LOCAL_MODEL_FILE)\n",
    "pprint(local_model.predict(input_data, full=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to predict many rows at once, you can use the **BigMLer** command line, that uses this local **Model** object to create the predictions and store it in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-09-10 23:25:48] Retrieving model. https://bigml.com/dashboard/model/5b96d2532774cb43d1002046\n",
      "[2018-09-10 23:25:48] Creating local predictions.\n",
      "\n",
      "Generated files:\n",
      "\n",
      " predictions\n",
      "  bigmler_sessions\n",
      "  predictions.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID = ratio_model['resource']\n",
    "!bigmler --test data/churn-test.csv --model $MODEL_ID --output-dir predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if you prefer the predictions to be computed remotely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-09-10 23:26:46] Retrieving model. https://bigml.com/dashboard/model/5b96d2532774cb43d1002046\n",
      "[2018-09-10 23:26:47] Creating test source.\n",
      "[2018-09-10 23:26:51] Source created: https://bigml.com/dashboard/source/5b96e197c7736e657b001ce4\n",
      "[2018-09-10 23:26:51] Creating dataset.\n",
      "[2018-09-10 23:26:54] Dataset created: https://bigml.com/dashboard/dataset/5b96e19cc7736e6580000324\n",
      "[2018-09-10 23:26:54] Creating batch prediction.\n",
      "[2018-09-10 23:26:57] Batch prediction created: https://bigml.com/dashboard/batchprediction/5b96e19fc7736e65830002f3\n",
      "\n",
      "Generated files:\n",
      "\n",
      " remote-predictions\n",
      "  bigmler_sessions\n",
      "  source_test\n",
      "  predictions.csv\n",
      "  dataset_test\n",
      "  batch_prediction\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bigmler --test data/churn-test.csv --model $MODEL_ID --output-dir remote-predictions --remote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Basic prediction workflow\n",
    "\n",
    "To sum up, the basic prediction workflow will need some steps:\n",
    "\n",
    "- Upload the data to create a Source\n",
    "- Summarize all data in a Dataset\n",
    "- Create a Model from the Dataset\n",
    "- Use the Model to produce a prediction for the new data\n",
    "\n",
    "Using the diabetes example, to produce this workflow using the bindings you would use this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "true\n",
      "false\n",
      "false\n",
      "false\n",
      "true\n",
      "false\n",
      "true\n",
      "false\n",
      "true\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "true\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "true\n",
      "false\n",
      "true\n",
      "true\n",
      "true\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from bigml.api import BigML\n",
    "from bigml.model import Model\n",
    "\n",
    "api = BigML()\n",
    "source = api.create_source(DIABETES_FILE, {\"project\": PROJECT})\n",
    "api.ok(source)\n",
    "dataset = api.create_dataset(source)\n",
    "api.ok(dataset)\n",
    "model = api.create_model(dataset)\n",
    "api.ok(model)\n",
    "\n",
    "local_model = Model(model)\n",
    "with open(\"data/diabetes_test.csv\") as test_handler:\n",
    "    reader = csv.DictReader(test_handler)\n",
    "    for input_data in reader:\n",
    "    # predicting for all rows\n",
    "        print(local_model.predict(input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same could be achieved in a single line command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-09-10 23:44:40] Creating source.\n",
      "[2018-09-10 23:44:43] Source created: https://bigml.com/dashboard/source/5b96e5c9c7736e657b001d16\n",
      "[2018-09-10 23:44:43] Creating dataset.\n",
      "[2018-09-10 23:44:46] Dataset created: https://bigml.com/dashboard/dataset/5b96e5ccc7736e657b001d19\n",
      "[2018-09-10 23:44:46] Creating model.\n",
      "[2018-09-10 23:44:50] Model created: https://bigml.com/dashboard/model/5b96e5ce92527314e100207d\n",
      "[2018-09-10 23:44:50] Retrieving model. https://bigml.com/dashboard/model/5b96e5ce92527314e100207d\n",
      "[2018-09-10 23:44:50] Creating local predictions.\n",
      "\n",
      "Generated files:\n",
      "\n",
      " diabetes-prediction\n",
      "  bigmler_sessions\n",
      "  predictions.csv\n",
      "  models\n",
      "  dataset\n",
      "  source\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bigmler --train data/ext_diabetes.csv --test data/diabetes_test.csv \\\n",
    "         --output-dir diabetes-prediction --project-id $PROJECT \\\n",
    "         --name \"Diabetes with bigmler\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we want to evaluate this model, we can add the **--evaluate** flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-09-10 23:45:06] Creating source.\n",
      "[2018-09-10 23:45:11] Source created: https://bigml.com/dashboard/source/5b96e5e3c7736e657b001d1c\n",
      "[2018-09-10 23:45:11] Creating dataset.\n",
      "[2018-09-10 23:45:14] Dataset created: https://bigml.com/dashboard/dataset/5b96e5e892527314e1002080\n",
      "[2018-09-10 23:45:14] Creating model.\n",
      "[2018-09-10 23:45:19] Model created: https://bigml.com/dashboard/model/5b96e5ea2774cb43c8000262\n",
      "[2018-09-10 23:45:19] Creating evaluations.\n",
      "[2018-09-10 23:45:22] Evaluation created: https://bigml.com/dashboard/evaluation/5b96e5f0c7736e657e000317\n",
      "[2018-09-10 23:45:22] Retrieving evaluation. https://bigml.com/dashboard/evaluation/5b96e5f0c7736e657e000317\n",
      "\n",
      "Generated files:\n",
      "\n",
      " diabetes-eval\n",
      "  bigmler_sessions\n",
      "  evaluation.txt\n",
      "  evaluation.json\n",
      "  models\n",
      "  evaluations\n",
      "  dataset\n",
      "  source\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bigmler --train data/ext_diabetes.csv --output-dir diabetes-eval --evaluate \\\n",
    "         --project-id $PROJECT --name \"Diabetes evaluated with BigMLer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers removal workflow \n",
    "We can try to improve that performance by removing the top outliers from the dataset before modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-09-10 23:52:59] Retrieving dataset. https://bigml.com/dashboard/dataset/5b96e53492527314d4000246\n",
      "[2018-09-10 23:53:00] Creating anomaly detector.\n",
      "[2018-09-10 23:53:13] Anomaly created: https://bigml.com/dashboard/anomaly/5b96e7bc2774cb43c8000265\n",
      "[2018-09-10 23:53:14] Creating dataset.\n",
      "[2018-09-10 23:53:17] Dataset created: https://bigml.com/dashboard/dataset/5b96e7cb92527314e500026a\n",
      "\n",
      "Generated files:\n",
      "\n",
      " diabetes_anomaly\n",
      "  bigmler_sessions\n",
      "  dataset_gen\n",
      "  anomalies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATASET_ID = dataset['resource']\n",
    "!bigmler anomaly --dataset $DATASET_ID \\\n",
    "                 --anomaly-fields \"insulin,pregnancies,plasma glucose,diabetes\" \\\n",
    "                 --top-n 2 --anomalies-dataset out --output-dir diabetes_anomaly \\\n",
    "                 --project-id $PROJECT --name \"Clean diabetes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And evaluating the model built on the clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-09-10 23:54:14] Retrieving dataset. https://bigml.com/dashboard/dataset/5b96e7cb92527314e500026a\n",
      "[2018-09-10 23:54:14] Creating model.\n",
      "[2018-09-10 23:54:22] Model created: https://bigml.com/dashboard/model/5b96e80bc7736e657b001d2b\n",
      "[2018-09-10 23:54:22] Creating evaluations.\n",
      "[2018-09-10 23:54:31] Evaluation created: https://bigml.com/dashboard/evaluation/5b96e815c7736e657b001d2e\n",
      "[2018-09-10 23:54:31] Retrieving evaluation. https://bigml.com/dashboard/evaluation/5b96e815c7736e657b001d2e\n",
      "\n",
      "Generated files:\n",
      "\n",
      " diabetes-clean-eval\n",
      "  bigmler_sessions\n",
      "  evaluation.txt\n",
      "  evaluation.json\n",
      "  models\n",
      "  evaluations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bigmler --datasets diabetes_anomaly/dataset_gen --output-dir diabetes-clean-eval \\\n",
    "         --project-id $PROJECT --evaluate --name \"Clean diabetes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrain with cumulative data\n",
    "\n",
    "Usually, you start your project uploading a sample of data and playing with it till you discover the workflow that gives you acceptable results. Then, the rest of data is uploaded and you'd like to repeat the same process on the accumulated data. **BigMLer** can help you do that. In this example, we do a regular model creation workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-09-10 21:48:31] Creating source.\n",
      "[2018-09-10 21:48:34] Source created: https://bigml.com/dashboard/source/5b96ca90c7736e65830002dc\n",
      "[2018-09-10 21:48:34] Creating dataset.\n",
      "[2018-09-10 21:48:37] Dataset created: https://bigml.com/dashboard/dataset/5b96ca9392527314dd0002b1\n",
      "[2018-09-10 21:48:37] Creating model.\n",
      "[2018-09-10 21:48:40] Model created: https://bigml.com/dashboard/model/5b96ca952774cb43d100201d\n",
      "\n",
      "Generated files:\n",
      "\n",
      " initial_model\n",
      "  bigmler_sessions\n",
      "  models\n",
      "  dataset\n",
      "  source\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bigmler --train data/ext_diabetes_1.csv \\\n",
    "         --tag best_diabetes \\\n",
    "         --name \"Cumulative diabetes data\" \\\n",
    "         --project-id $PROJECT \\\n",
    "         --output-dir ./initial_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And after that, new data is uploaded and the same process is reproduced on the accumulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-09-10 21:48:45] Creating execution.\n",
      "[2018-09-10 21:49:01] Execution created: https://bigml.com/dashboard/execution/5b96ca9ec7736e657b001c60\n",
      "\n",
      "Generated files:\n",
      "\n",
      " accumulative_retrain\n",
      "  bigmler_sessions\n",
      "  execution\n",
      "  whizzml_results.txt\n",
      "  whizzml_results.json\n",
      "\n",
      "[2018-09-10 21:49:01] Retrieving execution. https://bigml.com/dashboard/execution/5b96ca9ec7736e657b001c60\n",
      "[2018-09-10 21:49:02] Creating source.\n",
      "[2018-09-10 21:49:04] Source created: https://bigml.com/dashboard/source/5b96caae2774cb43d1002020\n",
      "\n",
      "Generated files:\n",
      "\n",
      " accumulative_retrain\n",
      "  bigmler_sessions\n",
      "  execution\n",
      "  whizzml_results.txt\n",
      "  whizzml_results.json\n",
      "  source\n",
      "\n",
      "[2018-09-10 21:49:04] Creating execution.\n",
      "[2018-09-10 21:49:16] Execution created: https://bigml.com/dashboard/execution/5b96cab192527314e1001fc0\n",
      "\n",
      "Generated files:\n",
      "\n",
      " accumulative_retrain\n",
      "  bigmler_sessions\n",
      "  execution\n",
      "  whizzml_results.txt\n",
      "  whizzml_results.json\n",
      "  source\n",
      "\n",
      "The new retrained model is: model/5b96cab73980b563dd018409.\n",
      "You can use the\n",
      "\n",
      "https://bigml.io/andromeda/model?username=merce_demo;api_key=dc0d33828c638840934f8bc004099b41d664b421;limit=1;full=yes;tags=best_diabetes\n",
      "\n",
      "query to retrieve the latest retrained model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bigmler retrain --add data/ext_diabetes_2.csv \\\n",
    "                 --model-tag best_diabetes \\\n",
    "                 --output-dir accumulative_retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
